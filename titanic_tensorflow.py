# -*- coding: utf-8 -*-
"""titanic_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QHW-dt3VmV24AYFtlsdmIcvUow_6dcJy
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import sklearn
import os


os.listdir()

dataset = pd.read_csv("./train.csv")
testset = pd.read_csv("./test.csv")

values = {'Pclass': 0, 'Sex': 'female', 'Age': 20.0, 'FamilySize': 0}
dataset=dataset.fillna(value=values)

testset=testset.fillna(value=values)

label = dataset[['Survived']].values
#print(label)

x=[dataset,testset]
for change in x:
    change['Sex']=change['Sex'].map({'female':0,'male':1}).astype(int)
    change['FamilySize'] = change['SibSp'] + change['Parch'] + 1
    #dataset['IsAlone'] = 1  # initialize to yes/1 is alone

    #dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0

use_collumn=['Pclass','Sex','Age','FamilySize']
data = dataset[use_collumn].values
testdata = testset[use_collumn].values

y_onehot=np.zeros(shape=(label.shape[0],2))
for i in range(label.shape[0]):
  x=label[i]
   #print(label)
  if x==0:
    y_onehot[i,0]=1
  if x==1:
    y_onehot[i,1]=1

print(y_onehot[0:4])

print(type(label))
label.shape

data.shape

from sklearn.model_selection import train_test_split
X_train, X_validation, y_train, y_validation = train_test_split(data,y_onehot, test_size=0.3, random_state=1)

X_train.shape

X_train

y_train.shape

x_input = tf.placeholder(tf.float32,shape= [None,4],name = 'x_input')
y_input = tf.placeholder(tf.float32,shape= [None,2],name = 'y_input')

weight_1=tf.Variable(tf.random.truncated_normal(shape=(6,4)),name='weight_1')
bias_1=tf.Variable(tf.random.truncated_normal(shape=(1,6)),name='bias_1')

weight_2=tf.Variable(tf.random.truncated_normal(shape=(5,6)),name='weight_2')
bias_2=tf.Variable(tf.random.truncated_normal(shape=(1,5)),name='bias_2')

weight_3=tf.Variable(tf.random.truncated_normal(shape=(2,5)),name='weight_3')
bias_3=tf.Variable(tf.random.truncated_normal(shape=(1,2)),name='bias_3')

out_layer_1=tf.math.add(tf.linalg.matmul(x_input,tf.transpose(weight_1)),bias_1)
activate_layer_1=tf.nn.relu(out_layer_1)
out_layer_2=tf.math.add(tf.linalg.matmul(activate_layer_1,tf.transpose(weight_2)),bias_2)
activate_layer_2=tf.nn.relu(out_layer_2)
logit=tf.math.add(tf.linalg.matmul(activate_layer_2,tf.transpose(weight_3)),bias_3)

predict=tf.math.argmax(logit,axis=1)


loss=tf.nn.softmax_cross_entropy_with_logits(
    labels=y_input,
    logits=logit,
)
loss=tf.math.reduce_sum(loss)
# #===== end model===

# #===== start learning algorithm ====
optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.001)

thaotac_gan_cho_tat_ca_cac_bien=optimizer.minimize(loss=loss)

sess=tf.Session()

sess.run(tf.global_variables_initializer())

print(sess.run([loss],feed_dict={x_input:X_train,y_input:y_train}))

for _ in range(300):
  sess.run([thaotac_gan_cho_tat_ca_cac_bien],feed_dict={x_input:X_train,y_input:y_train})

print(sess.run([loss],feed_dict={x_input:X_train,y_input:y_train}))

predict_result=sess.run([predict],feed_dict={x_input:X_train})[0]

def accuracy(predict,label):
  y_decode=np.argmax(label,axis=1)
  count=0
  for i in range(0,y_decode.shape[0]):
    if predict[i]==y_decode[i]:
      count+=1
  print(count/y_decode.shape[0])
accuracy(predict_result,y_train)

predict_result=sess.run([predict],feed_dict={x_input:X_test})[0]
accuracy(predict_result,y_test)

predict_result

result = sess.run([predict],feed_dict={x_input:testdata})[0]
accuracy(predict_result,y_test)

index=[testset['PassengerId']]
df=pd.DataFrame(data=result,index=testset['PassengerId'],columns=['Survived'])
df.to_csv('a.csv',header=True)


